{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'Acacia', 2: 'Adenanthera microsperma', 3: 'Adenium species', 4: 'Anacardium occidentale', 5: 'Annona squamosa', 6: 'Artocarpus altilis', 7: 'Artocarpus heterophyllus', 8: 'Barringtonia acutangula', 9: 'Cananga odorata', 10: 'Carica papaya', 11: 'Casuarina equisetifolia', 12: 'Cedrus', 13: 'Chrysophyllum cainino', 14: 'Citrus aurantiifolia', 15: 'Citrus grandis', 16: 'Cocos nucifera', 17: 'Dalbergia oliveri', 18: 'Delonix regia', 19: 'Dipterocarpus alatus', 20: 'Erythrina fusca', 21: 'Eucalyptus', 22: 'Ficus microcarpa', 23: 'Ficus racemosa', 24: 'Gmelina arborea Roxb', 25: 'Hevea brasiliensis', 26: 'Hopea', 27: 'Khaya senegalensis', 28: 'Khaya senegalensis A.Juss', 29: 'Lagerstroemia speciosa', 30: 'Magnolia alba', 31: 'Mangifera', 32: 'Melaleuca', 33: 'Melia azedarach', 34: 'Musa', 35: 'Nephelium lappaceum', 36: 'Persea', 37: 'Polyalthia longifolia', 38: 'Prunnus', 39: 'Prunus salicina', 40: 'Psidium guajava', 41: 'Pterocarpus macrocarpus', 42: 'Senna siamea', 43: 'Spondias mombin L', 44: 'Syzygium nervosum', 45: 'Tamarindus indica', 46: 'Tectona grandis', 47: 'Terminalia catappa', 48: 'Veitchia merrilli', 49: 'Wrightia', 50: 'Wrightia religiosa'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "x=os.walk(r\"./data\")\n",
    "x=list(x)\n",
    "entries={}\n",
    "it = 0\n",
    "for i in range(1,len(x)) :\n",
    "\n",
    "    entries[i]=x[i][0].split(\"\\\\\")[-1]\n",
    "    \n",
    "print(entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDefaultHiddenLayers(inputs):\n",
    "        cnn = tf.keras.layers.Conv2D(16, (3, 3), padding=\"same\",activation=\"relu\")(inputs)\n",
    "        # cnn = tf.keras.layers.core.Activation(\"relu\")(cnn)\n",
    "        cnn = tf.keras.layers.BatchNormalization(axis=-1)(cnn)\n",
    "        cnn = tf.keras.layers.MaxPooling2D(pool_size=(3, 3))(cnn)\n",
    "        cnn = tf.keras.layers.Dropout(0.25)(cnn)\n",
    "        cnn = tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\")(cnn)\n",
    "        cnn = tf.keras.layers.Activation(\"relu\")(cnn)\n",
    "        cnn = tf.keras.layers.BatchNormalization(axis=-1)(cnn)\n",
    "        cnn = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(cnn)\n",
    "        cnn = tf.keras.layers.Dropout(0.25)(cnn)\n",
    "        cnn = tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\")(cnn)\n",
    "        cnn = tf.keras.layers.Activation(\"relu\")(cnn)\n",
    "        cnn = tf.keras.layers.BatchNormalization(axis=-1)(cnn)\n",
    "        cnn = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(cnn)\n",
    "        cnn = tf.keras.layers.Dropout(0.25)(cnn)\n",
    "        return cnn\n",
    "def makeModal(inputs,class_dict):\n",
    "    cnn=makeDefaultHiddenLayers(inputs)\n",
    "    cnn = tf.keras.layers.Flatten()(cnn)\n",
    "    cnn = tf.keras.layers.Dense(128)(cnn)\n",
    "    cnn = tf.keras.layers.Activation(\"relu\")(cnn)\n",
    "    cnn = tf.keras.layers.BatchNormalization()(cnn)\n",
    "    cnn = tf.keras.layers.Dropout(0.5)(cnn)\n",
    "    cnn = tf.keras.layers.Dense(class_dict)(cnn)\n",
    "    cnn = tf.keras.layers.Activation(\"softmax\", name=\"Bark_Output\")(cnn)\n",
    "\n",
    "    return cnn\n",
    "def assemble(width,height,class_dict):\n",
    "    inputs = tf.keras.layers.Input(shape=(height, width, 3))\n",
    "    cnnOutputLayers=makeModal(inputs,class_dict)\n",
    "    model=tf.keras.models.Model(inputs=inputs,outputs = [cnnOutputLayers],name=\"face_net\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 50)\n"
     ]
    }
   ],
   "source": [
    "X=assemble(303, 404,50)\n",
    "print(X.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5578 files belonging to 50 classes.\n",
      "Using 4463 files for training.\n",
      "Using 1115 files for validation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='data/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(404, 303),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "140/140 [==============================] - ETA: 0s - loss: 2.7541 - accuracy: 0.2978WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001C18252B048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001C18252B048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "140/140 [==============================] - 253s 2s/step - loss: 2.7541 - accuracy: 0.2978 - val_loss: 2.3589 - val_accuracy: 0.4350\n",
      "Epoch 2/25\n",
      "140/140 [==============================] - 246s 2s/step - loss: 1.5666 - accuracy: 0.5958 - val_loss: 1.7309 - val_accuracy: 0.5749\n",
      "Epoch 3/25\n",
      "140/140 [==============================] - 258s 2s/step - loss: 1.0168 - accuracy: 0.7461 - val_loss: 1.3040 - val_accuracy: 0.6879\n",
      "Epoch 4/25\n",
      "140/140 [==============================] - 246s 2s/step - loss: 0.6439 - accuracy: 0.8485 - val_loss: 1.3923 - val_accuracy: 0.6188\n",
      "Epoch 5/25\n",
      "140/140 [==============================] - 224s 2s/step - loss: 0.4245 - accuracy: 0.9079 - val_loss: 1.0803 - val_accuracy: 0.7247\n",
      "Epoch 6/25\n",
      "140/140 [==============================] - 229s 2s/step - loss: 0.2980 - accuracy: 0.9386 - val_loss: 1.1659 - val_accuracy: 0.7049\n",
      "Epoch 7/25\n",
      "140/140 [==============================] - 217s 2s/step - loss: 0.2356 - accuracy: 0.9503 - val_loss: 2.4647 - val_accuracy: 0.4906\n",
      "Epoch 8/25\n",
      "140/140 [==============================] - 230s 2s/step - loss: 0.1688 - accuracy: 0.9666 - val_loss: 0.9544 - val_accuracy: 0.7587\n",
      "Epoch 9/25\n",
      "140/140 [==============================] - 214s 2s/step - loss: 0.1209 - accuracy: 0.9798 - val_loss: 0.7554 - val_accuracy: 0.7910\n",
      "Epoch 10/25\n",
      "140/140 [==============================] - 214s 2s/step - loss: 0.1070 - accuracy: 0.9789 - val_loss: 1.2384 - val_accuracy: 0.6664\n",
      "Epoch 11/25\n",
      "140/140 [==============================] - 209s 1s/step - loss: 0.0985 - accuracy: 0.9805 - val_loss: 1.2000 - val_accuracy: 0.7031\n",
      "Epoch 12/25\n",
      "140/140 [==============================] - 206s 1s/step - loss: 0.0858 - accuracy: 0.9848 - val_loss: 0.8428 - val_accuracy: 0.7991\n",
      "Epoch 13/25\n",
      "140/140 [==============================] - 211s 2s/step - loss: 0.0723 - accuracy: 0.9870 - val_loss: 1.4850 - val_accuracy: 0.6457\n",
      "Epoch 14/25\n",
      "140/140 [==============================] - 207s 1s/step - loss: 0.0604 - accuracy: 0.9886 - val_loss: 1.3855 - val_accuracy: 0.7354\n",
      "Epoch 15/25\n",
      "140/140 [==============================] - 218s 2s/step - loss: 0.0626 - accuracy: 0.9879 - val_loss: 1.9356 - val_accuracy: 0.7094\n",
      "Epoch 16/25\n",
      "140/140 [==============================] - 205s 1s/step - loss: 0.0749 - accuracy: 0.9825 - val_loss: 1.3212 - val_accuracy: 0.6996\n",
      "Epoch 17/25\n",
      "140/140 [==============================] - 231s 2s/step - loss: 0.0630 - accuracy: 0.9875 - val_loss: 2.5307 - val_accuracy: 0.7874\n",
      "Epoch 18/25\n",
      "140/140 [==============================] - 215s 2s/step - loss: 0.0549 - accuracy: 0.9875 - val_loss: 1.4901 - val_accuracy: 0.7596\n",
      "Epoch 19/25\n",
      "140/140 [==============================] - 206s 1s/step - loss: 0.0546 - accuracy: 0.9875 - val_loss: 1.1234 - val_accuracy: 0.7821\n",
      "Epoch 20/25\n",
      "140/140 [==============================] - 201s 1s/step - loss: 0.0546 - accuracy: 0.9886 - val_loss: 1.4850 - val_accuracy: 0.6780\n",
      "Epoch 21/25\n",
      "140/140 [==============================] - 203s 1s/step - loss: 0.0606 - accuracy: 0.9861 - val_loss: 1.4845 - val_accuracy: 0.6915\n",
      "Epoch 22/25\n",
      "140/140 [==============================] - 201s 1s/step - loss: 0.0509 - accuracy: 0.9877 - val_loss: 1.7173 - val_accuracy: 0.7740\n",
      "Epoch 23/25\n",
      "140/140 [==============================] - 192s 1s/step - loss: 0.0611 - accuracy: 0.9852 - val_loss: 1.5425 - val_accuracy: 0.7094\n",
      "Epoch 24/25\n",
      "140/140 [==============================] - 209s 1s/step - loss: 0.0694 - accuracy: 0.9825 - val_loss: 4.1411 - val_accuracy: 0.4179\n",
      "Epoch 25/25\n",
      "140/140 [==============================] - 208s 1s/step - loss: 0.0465 - accuracy: 0.9877 - val_loss: 1.0205 - val_accuracy: 0.7731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1e72ea408>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.fit(x = dataset[0], validation_data = dataset[1], epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "Acacia\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = tf.keras.utils.load_img(r'C:\\Users\\PRANAV ARYA\\Documents\\GitHub\\Bark_rec\\data\\Acacia\\IMG_6348.JPG', target_size = (404,303))\n",
    "test_image = tf.keras.utils.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = X.predict(test_image)\n",
    "maxIndex=0\n",
    "for i in range(1,50):\n",
    "      if result[0][i]>result[0][maxIndex]:\n",
    "            maxIndex=i\n",
    "print(entries[maxIndex+1])\n",
    "# if result[0][0] == 1:\n",
    "#   prediction = 'dog'\n",
    "# else:\n",
    "#   prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b08f8407356b161a2e1ac7d2ca0aa1e0ec9901f167337b26f19bf60d60a06b81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
